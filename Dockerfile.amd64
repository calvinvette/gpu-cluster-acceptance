# ---- builder ----
# FROM nvcr.io/nvidia/cuda:12.4.1-devel-ubuntu22.04 AS builder
FROM docker.io/nvidia/cuda:12.4.1-devel-ubuntu22.04 AS builder

RUN apt-get update && DEBIAN_FRONTEND=noninteractive apt-get install -y \
    git build-essential cmake libopenmpi-dev openmpi-bin && \
    rm -rf /var/lib/apt/lists/*

# nvbandwidth
RUN git clone --depth 1 https://github.com/NVIDIA/nvbandwidth /opt/nvbandwidth
WORKDIR /opt/nvbandwidth
# RUN . ./debian_install.sh
RUN apt-get -y update
RUN apt-get install -y software-properties-common apt-transport-https curl wget
RUN apt-get -y update
RUN add-apt-repository universe
RUN apt-get -y update
RUN apt-get install -y libboost-all-dev libboost-program-options-dev
RUN mkdir -p /opt/nvbandwidth/build
WORKDIR /opt/nvbandwidth/build
RUN cmake ..
RUN make -C /opt/nvbandwidth/build

WORKDIR /tmp
# RUN curl -LO https://content.mellanox.com/hpc/hpc-x/v2.23/hpcx-v2.23-gcc-inbox-ubuntu22.04-cuda12-x86_64.tbz
RUN curl -LO 'https://content.mellanox.com/hpc/hpc-x/v2.23/hpcx-v2.23-gcc-doca_ofed-ubuntu22.04-cuda12-x86_64.tbz'
# RUN wget -O 'https://content.mellanox.com/hpc/hpc-x/v2.23/hpcx-v2.23-gcc-doca_ofed-ubuntu22.04-cuda12-x86_64.tbz'
RUN tar -C /opt -xvpf hpcx-v2.23-gcc-doca_ofed-ubuntu22.04-cuda12-x86_64.tbz
RUN rm /tmp/hpcx-v2.23-gcc-doca_ofed-ubuntu22.04-cuda12-x86_64.tbz
RUN ln -s /opt/hpcx-v2.23-gcc-doca_ofed-ubuntu22.04-cuda12-x86_64 /opt/hpcx
# RUN . /opt/hpcx/hpcx-init.sh

# nccl-tests
RUN git clone --depth 1 https://github.com/NVIDIA/nccl-tests /opt/nccl-tests
# RUN . /opt/hpcx/hpcx-init.sh && make -C /opt/nccl-tests MPI=1
ENV HPCX_DIR="/opt/hpcx"
ENV HPCX_UCX_DIR="/opt/hpcx/ucx"
ENV HPCX_UCC_DIR="/opt/hpcx/ucc"
ENV HPCX_SHARP_DIR="/opt/hpcx/sharp"
ENV HPCX_HCOLL_DIR="/opt/hpcx/hcoll"
ENV HPCX_MPI_DIR="/opt/hpcx/ompi"
ENV HPCX_OSHMEM_DIR="/opt/hpcx/ompi"
ENV HPCX_MPI_TESTS_DIR="/opt/hpcx/ompi/tests"
ENV HPCX_OSU_DIR="/opt/hpcx/ompi/tests/osu-micro-benchmarks"
ENV HPCX_OSU_CUDA_DIR="/opt/hpcx/ompi/tests/osu-micro-benchmarks-cuda"
ENV HPCX_CLUSTERKIT_DIR="/opt/hpcx/clusterkit"
ENV HPCX_NCCLNET_PLUGIN_DIR="/opt/hpcx/ncclnet_plugin"
ENV HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR="/opt/hpcx/nccl_rdma_sharp_plugin"
ENV OMPI_HOME="/opt/hpcx/ompi"
ENV MPI_HOME="/opt/hpcx/ompi"
ENV OSHMEM_HOME="/opt/hpcx/ompi"
ENV SHMEM_HOME="/opt/hpcx/ompi"
ENV PATH="/home/calvin/.local/bin:/home/calvin/bin:/home/calvin/.nebius/bin/:/home/calvin/.krew/bin:/home/calvin/miniconda3/envs/torch28/bin:/home/calvin/miniconda3/condabin:/home/calvin/.cargo/bin:/opt/go/bin:/home/calvin/.nvm/versions/node/v21.6.2/bin:/usr/local/cuda-12/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/var/lib/rancher/rke2/bin:/var/lib/rancher/rke2/bin"
ENV LD_LIBRARY_PATH="/usr/local/lib:/usr/local/cuda-12/lib64:"
RUN make -C /opt/nccl-tests MPI=1




# ---- runtime ----
FROM nvcr.io/nvidia/cuda:12.4.1-runtime-ubuntu22.04

LABEL org.opencontainers.image.licenses="AGPL-3.0-only"

# minimal runtime deps
RUN apt-get update && DEBIAN_FRONTEND=noninteractive apt-get install -y \
    python3 python3-pip python3-venv \
    rdma-core libibverbs1 libopenmpi3 openmpi-bin \
    pciutils iproute2 iputils-ping jq fio && \
    rm -rf /var/lib/apt/lists/*

# (Optional) DCGM tools inside container if you want to run dcgmi from here
# RUN apt-get update && apt-get install -y dcgm dcgm-exporter && rm -rf /var/lib/apt/lists/*

# Python deps (install only what you need)
COPY pyproject.toml /app/pyproject.toml
RUN pip3 install --no-cache-dir --upgrade pip
RUN pip3 install packaging torch

# PyTorch + CUDA 12.4 wheel (smaller than NGC PyTorch image)
RUN pip3 install --no-cache-dir --index-url https://download.pytorch.org/whl/cu124 \
    torch \
    torchvision \
    torchaudio

RUN pip3 install -e /app

# Copy binaries from builder
COPY --from=builder /opt/nvbandwidth /opt/nvbandwidth
COPY --from=builder /opt/nccl-tests /opt/nccl-tests

# Non-root user & workspace
RUN useradd -ms /bin/bash trainer && mkdir -p /workspace && chown -R trainer:trainer /workspace /opt
USER trainer
WORKDIR /workspace

COPY --chown=trainer:trainer scripts/ ./scripts/
COPY --chown=trainer:trainer training/ ./training/
COPY --chown=trainer:trainer configs/ ./configs/
ENV PATH="/opt/nvbandwidth:${PATH}"